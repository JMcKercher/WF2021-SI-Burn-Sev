## Random Forest Classification
<details>
Within this section of the notebook we will use smilerandom forest from Google Earth Engine to classify the spetral indice of your choice and accurately map the sevreity of the Wooroloo Bushfire 2021
<details>

#Create a combined variable of all indices
AllIndex = ['CSI_A1', 'CSI_B1', 'CSI_D1', 'CSI_E1', 'dNBR_A1','dNBR_B1', 'dNBR_C1', 'dNBR_E1', 'RdNBR_A1','RdNBR_B1', 
            'RdNBR_C1', 'RdNBR_D1', 'RBR_A1','RBR_B1', 'RBR_C1', 'RBR_D1', 'RBR_E1', 'dNBR_F1', 'RBR_F1']
RF_F1dNBR = ['dNBR_F1'] #Transforms the image to a listed image
RF_F1RBR = ['RBR_F1'] #Transforms the image to a listed image

# Upload the table and convert it to a feature collection so EE can read it. 
'''This function calls the CSV file from google earth engine directly, the file is uploaded into the assests area of the program and called by the below code'''
# Contains results from all indices
RFCdat = ee.FeatureCollection('projects/ee-jmckercher/assets/GC_RFC') # CSV from GEE
'''Note: Class variables must be numeric and start from 0: 0 = Unburnt, 1 = Low, 2 = Moderate, 3 = High'''
# Pull training and test data from all indices 
train = RFCdat.filter(ee.Filter.stringContains("train_test", 'Train')) 
test = RFCdat.filter(ee.Filter.stringContains("train_test", 'Test'))

# Contains results of just the dNBR min 64 Days
dNBRF1_rf = ee.FeatureCollection('projects/ee-jmckercher/assets/GC_RFC_dNBR')
# Call EE to filter train data points and test data points to divide the data set into test and train sets.
F1_train = dNBRF1_rf.filter(ee.Filter.stringContains("train_test", 'Train')) #Specifically for dNBR Min 64
F1_test = dNBRF1_rf.filter(ee.Filter.stringContains("train_test", 'Test')) #Specifically for dNBR Min 64

# Contains results of just the RBR min 64 Days with the outliers removed 
RBRF1_rf = ee.FeatureCollection('projects/ee-jmckercher/assets/RFC_RBR_ORem')
# Call EE to filter train data points and test data points to divide the data set into test and train sets.
RBRF1_train = RBRF1_rf.filter(ee.Filter.stringContains("train_test", 'Train')) #Specifically for dNBR Min 64
RBRF1_test = RBRF1_rf.filter(ee.Filter.stringContains("train_test", 'Test')) #Specifically for dNBR Min 64

# Random Forest Classifier Layout 
'''classifier = ee.Classifier.smileRandomForest(500, seed=123).train(
     features= train, 
     classProperty= 'SA_class',
     inputProperties= AllIndex)'''

# dNBR min Classifier
F1_classifier = ee.Classifier.smileRandomForest(500, seed=123).train(
     features= F1_train, 
     classProperty= 'SA_class',
     inputProperties= RF_F1dNBR) #Increasing amount of trees to 200 increases accuracy. 

# dNBR min Classifier
RBRF1_classifier = ee.Classifier.smileRandomForest(500, seed=123).train(
     features= RBRF1_train, 
     classProperty= 'SA_class',
     inputProperties= RF_F1RBR) #Increasing amount of trees to 200 increases accuracy. 

RBRF1_trainAcc = RBRF1_classifier.confusionMatrix()

# Classify the validation data.
RBRF1_Validate = RBRF1_test.classify(RBRF1_classifier)
RBRF1_Mat = RBRF1_Validate.errorMatrix('SA_class', 'classification')
RBRF1_Mat_info = RBRF1_Mat.getInfo()
print('Validation Accuracy', RBRF1_Mat.accuracy().getInfo())
print('Validation Kappa', RBRF1_Mat.kappa().getInfo())
print('Specified name and order of the rows and columns', RBRF1_Mat.order().getInfo()) # Returns the name and order of the rows and columns of the matrix.
print('Validation Confusion Matrix', RBRF1_Mat_info)
print('F-Score', RBRF1_Mat.fscore(1).getInfo()) # Computes the FÎ²-score for the confusion matrix: The higher an F-score, the more accurate a model is. The lower an F-score, the less accurate a model is.
print("Producer's accuracy", RBRF1_Mat.producersAccuracy().getInfo()) # Computes the producer's accuracy of a confusion matrix defined as (correct / total) for each column, the probability that a value in a given class was classified correctly.
print("Consumer's accuracy", RBRF1_Mat.consumersAccuracy().getInfo()) # Computes the consumer's accuracy (reliability) of a confusion matrix defined as (correct / total) for each row.
'''the probability that a value predicted to be in a certain class really is that class. The probability is based on the fraction of correctly predicted values to the total number of values predicted to be in a class'''
print('Results of Classifier','\n',RBRF1_classifier.explain().getInfo())
print('Training Accuracy: ', RBRF1_trainAcc.accuracy().getInfo())
print('Training Kappa: ', RBRF1_trainAcc.kappa().getInfo()) 

# Use the classifier to predict on an image
classified = RBR_F1.classify(RBRF1_classifier)
classified = classified.select('classification')
classified = classified.clip(WFg)
classified = classified.toByte() # only has values from 0-3 so reduce file size 
classified.getInfo()


# put it on the map
x,y = fire_poly.centroid().getInfo()['geometry']['coordinates']
# call geemap for plotting 
Map = geemap.Map(center=(y, x), zoom = 12, basemap = 'SATELLITE')
# add the fire polygon of interest
#Map.addLayer(fire_poly)

# Visualize burn area 
ClassParams = {'min': 0, 'max': 3, 'palette' : ['#4682B4','#FAFAD2', '#FF5400','#C71585']}

#Add a Legend
legend = {
    'Unburnt': '#4682B4',
    'Low': '#FAFAD2',
     'Moderate': '#FF5400',
    'High': '#C71585'}
Map.add_legend(title="Burn Severity", legend_dict=legend, position='bottomleft')
# Clip the Image that was classified & add to map to determine the pixel value of each classification
#dNBR_F1F = dNBR_F1.clip(WFg)
#Map.addLayer(dNBR_F1F, dNBRparams,'dNBR') # Image that was classified
RBR_F1F = dNBR_F1.clip(WFg)

WF_Area = RBR_F1F.clip(g)

#Map.addLayer(RBR_F1F, RBRparams,'RBR')
Map.addLayer(WF_Area, RBRparams,'RBR')
Map.addLayer(classified.select('classification'), ClassParams, 'RF Classification') # Classified Image
Map

