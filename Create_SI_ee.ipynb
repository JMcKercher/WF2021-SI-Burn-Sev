{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "34c05bc1",
      "metadata": {},
      "source": [
        "# Predict severity of any fire\n",
        "This section of the notebook will create several burn severity spectral indices for the Wooroloo Bushfire 2021. We require the date the fire started and geographical location of the area you want to measure."
      ]
    },
{
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16e616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee #",
    "ee.Authenticate()",
    "ee.Initialize()"
   ]
  },
{
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16e616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install the required programs using pip",
     "pip install geopandas",
     "pip install geemap",
     "pip install geemap[extra]", 
     "pip install geemap[all]"
   ]
  },
{
   "cell_type": "code",
   "execution_count": 1,
   "id": "7k3lhf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the programs",
     "import pandas as pd",
     "import geopandas as gpd",
     "import os",
     "import warnings",
     "warnings.filterwarnings('ignore')",
     "import numpy as np",
     "pd.set_option('display.float_format', lambda x: '%.0f' % x)",
     "import subprocess",
     "import sys",
     "sys.path.insert(0, 'utils')"
   ]
  },
{
  "cell_type": "code",
   "execution_count": 1,
   "id": "bft68s64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Files from local drive if required",
     "from google.colab import files",
     "uploaded = files.upload()",
     "for fn in uploaded.keys():",
     "print('User uploaded file "{name}" with length {length} bytes'.format(",
     "name=fn, length=len(uploaded[fn])))"
   ]
  },
{
  "cell_type": "code",
   "execution_count": 1,
   "id": "k47u1rfl",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the local files",
     "import landsat_utilsO as lsat",
     "import fires_utilsO as fu",
     "import paramsRF as params",
     "import vi as vi",
     "import geemap"
   ]
  },
{
  "cell_type": "code",
   "execution_count": 1,
   "id": "k467fh39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the shapefile of the fire you want to map",
     "from google.colab import files",
     "uploaded = files.upload()",
     "for fn in uploaded.keys():",
     "print('User uploaded file "{name}" with length {length} bytes'.format(",
     "name=fn, length=len(uploaded[fn])))"
   ]
  },
{
  "cell_type": "code",
   "execution_count": 1,
   "id": "0og3h1hn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a fire perimeter shapefile and convert to an aoi feature for EE to read",
     "gdf = gpd.read_file('f_ex2021.shp')",
     "gdf = gdf.to_crs("EPSG:4283")",
     "g = [i for i in gdf.geometry]",
     "x,y = g[0].exterior.coords.xy",
     "coords = np.dstack((x,y)).tolist()",
     "g = ee.Geometry.Polygon(coords)",
     "WFg = ee.Geometry.Rectangle([116.008687, -31.694399, 116.358957, -31.815356])",
     "fire_poly = ee.Feature(g)"
   ]
  },
{
  "cell_type": "code",
   "execution_count": 1,
   "id": "hithere5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the date information of the fire",
     "date_start = ee.Date('2021-01-30')",
     "date_end = ee.Date('2021-02-15')",
     "# get Landsat data for predicting fires",
     "oliCol = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')",
     "etmCol = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR')",
     "tmCol = ee.ImageCollection('LANDSAT/LT05/C01/T1_SR')",
     
     "#WF Fire filter for Landsat data for aoi and QA",
     "colFilter = ee.Filter.And(",
            "e.Filter.bounds(WFg),",
            "ee.Filter.lt('CLOUD_COVER', 50))""
   ]
  },
{
  "cell_type": "code",
   "execution_count": 1,
   "id": "howare67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter Landsat data for aoi and QA / Use this code to collect the images for the remaining fires",
     "'''colFilter = ee.Filter.And(",
            "ee.Filter.bounds(fire_poly.geometry()),",
              "ee.Filter.lt('CLOUD_COVER', 50))'''",
     
     "oliCol = oliCol.filter(colFilter).map(lsat.prepOli)",
     "etmCol = etmCol.filter(colFilter).map(lsat.prepEtm)",
     "tmCol = tmCol.filter(colFilter).map(lsat.prepEtm)",
     
     "landsat = oliCol.merge(etmCol).merge(tmCol)",
     "landsat = landsat.map(lsat.rescale)\",
                     ".map(vi.getNBR)\",
                     ".map(vi.getCSI)\",
                     ".map(vi.getRdNBR)\",
                     ".map(vi.getRBR)",

      "''' define the pre and post median composites to use for generating predictors '''",
      "fire_poly_buffer = fire_poly.buffer(2000)",

     "# get pre and post landsat dates",
     "date_pre = date_start.advance(-128, 'day')",
     "date_post = date_end.advance(64, 'day') # search window used post-fire",
     "seasonal_date_post = date_end.advance(128, 'day') #(Extended window for seasonal average)",
     
     "#Trial dates",
     "date_pre32 = date_start.advance(-32, 'day') ",
     "date_pre48 = date_start.advance(-48, 'day')",
     "date_pre64 = date_start.advance(-64, 'day')",
     "date_post48 =date_end.advance(48, 'day')",
     
     "# filter Landsat data for fire date and extent",
     "ls_temp = landsat.filter(ee.Filter.date(date_pre, date_post))\",
                 ".filterBounds(fire_poly_buffer.geometry())\",
                 ".select(['NBR', 'NDVI', 'NDWI', 'VARI', 'MSAVI', 'BAI', 'MIRBI', 'CSI', 'RdNBR', 'RBR'])",
     "# Seasonal",
     "ls_temp = landsat.filter(ee.Filter.date(date_pre, seasonal_date_post))\",
                 ".filterBounds(fire_poly_buffer.geometry())\",
                 ".select(['NBR', 'NDVI', 'NDWI', 'VARI', 'MSAVI', 'BAI', 'MIRBI', 'CSI', 'RdNBR', 'RBR'])",
     "# 64 Pre and Post",
     "ls_temp = landsat.filter(ee.Filter.date(date_pre64, date_post))\",
                 ".filterBounds(fire_poly_buffer.geometry())\",
                 ".select(['NBR', 'NDVI', 'NDWI', 'VARI', 'MSAVI', 'BAI', 'MIRBI', 'CSI', 'RdNBR', 'RBR'])",

     "#Define Pre and Post Image collection",
     "# Median",
     "pre = ls_temp.filterDate(date_pre, date_start.advance(-1, 'day')).median()",
     "post = ls_temp.filterDate(date_end.advance(1, 'day'), date_post).median() # Original 64-Days post",
     "seasonalpost = ls_temp.filterDate(date_end.advance(1, 'day'), seasonal_date_post).median() # 128-Day post",
     "# Maximum Seasonal",
     "maxpre = ls_temp.filterDate(date_pre, date_start.advance(-1, 'day')).max()",
     "maxpost = ls_temp.filterDate(date_end.advance(1, 'day'), seasonal_date_post).max()",
     "# Minimum Seasonal",
     "minpre = ls_temp.filterDate(date_pre, date_start.advance(-1, 'day')).min()",
     "minpost = ls_temp.filterDate(date_end.advance(1, 'day'), seasonal_date_post).min()",
     "# Minimum 64 Day Post",
     "minpost64 = ls_temp.filterDate(date_end.advance(1, 'day'), date_post).min() # Minimum 64 day post, different to SP",
     
     "# create a variable for the ee image collection with predicted fire severity data",
     "imcol = ee.ImageCollection('projects/euc-fire-sw-2022/assets/severity_pred_forested')",
     "# this imcol dataset has already been processed to remove non-forestest areas according to Hansen global forest cover"
   ]
  },
{
  "cell_type": "code",
   "execution_count": 1,
   "id": "youihope",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the SI ##",
     "from numpy.ma.core import sqrt",
     "''' start working with pre and post image composites to generate predictors'''",
     "# Median (64 Day Post)",
     "# NBR",
     "NBR_pre = pre.select('NBR').rename('NBR_pre')"dNBR_A1 = NBR_pre.subtract(post.select('NBR')).rename('dNBR_A1')",
     "# RdNBR",
     "RdNBR_A1pre = pre.select('RdNBR').rename('RdNBR_A1pre')",
     "RdNBR_A1 = dNBR_A1.divide(RdNBR_A1pre).rename('RdNBR_A1')",
     "# RBR",
     "RBR_A1pre = pre.select('RBR').rename('RBR_A1pre')",
     "RBR_A1 = dNBR_A1.divide(RBR_A1pre).rename('RBR_A1')",
     "# CSI",
     "CSI_A1 = post.select('CSI').rename('CSI_A1')",
     
     "# Median Seasonal (128 Day Post)",
     "# NBR",
     "NBR_B1 = pre.select('NBR').rename('NBR_B1pre')",
     "dNBR_B1 = NBR_B1.subtract(seasonalpost.select('NBR')).rename('dNBR_B1')",
     "# RdNBR",
     "RdNBR_B1pre = pre.select('RdNBR').rename('RdNBR_B1pre')",
     "RdNBR_B1 = dNBR_B1.divide(RdNBR_B1pre).rename('RdNBR_B1')",
     "# RBR",
     "RBR_B1pre = pre.select('RBR').rename('RBR_B1pre')",
     "RBR_B1 = dNBR_B1.divide(RBR_B1pre).rename('RBR_B1')",
     "# CSI",
     "CSI_B1 = seasonalpost.select('CSI').rename('CSI_B1')",
     
     "# Maximum Seasonal (128 Day post)",
     "# NBR",
     "NBR_C1 = maxpre.select('NBR').rename('NBR_C1')",
     "dNBR_C1 = NBR_C1.subtract(maxpost.select('NBR')).rename('dNBR_C1')",
     "# RdNBR",
     "RdNBR_C1pre = maxpre.select('RdNBR').rename('RdNBR_C1pre')",
     "RdNBR_C1 = dNBR_C1.divide(RdNBR_C1pre).rename('RdNBR_C1')",
     "# RBR",
     "RBR_C1pre = maxpre.select('RBR').rename('RBR_C1pre')",
     "RBR_C1 = dNBR_C1.divide(RBR_C1pre).rename('RBR_C1')",
     "# CSI",
     "CSI_C1 = maxpost.select('CSI').rename('CSI_C1')",
     
     "# Minimum Seasonal (128 Day Post)",
     "# NBR",
     "NBR_D1 = minpre.select('NBR').rename('NBR_D1')",
     "dNBR_D1 = NBR_D1.subtract(minpost.select('NBR')).rename('dNBR_D1')",
     "# RdNBR",
     "RdNBR_D1pre = minpre.select('RdNBR').rename('RdNBR_D1pre')",
     "RdNBR_D1 = dNBR_D1.divide(RdNBR_D1pre).rename('RdNBR_D1')",
     "# RBR",
     "RBR_D1pre = minpre.select('RBR').rename('RBR_D1pre')",
     "RBR_D1 = dNBR_D1.divide(RBR_D1pre).rename('RBR_D1')",
     "# CSI",
     "CSI_D1 = minpost.select('CSI').rename('CSI_D1')",
     
     "# Adjusted Indices based on results of RF model",
     "# RBR 128 day Max Pre 128 day Min Post RBR",
     "RBR_E1pre = maxpre.select('RBR').rename('RBR_E1pre')",
     "dNBR_E1 = NBR_D1.subtract(minpost.select('NBR')).rename('dNBR_E1')",
     "RBR_E1  = dNBR_E1.divide(RBR_E1pre).rename('RBR_E1')",
     "# dNBR Min 64 Day Post",
     "NBR_F1 = minpre64.select('NBR').rename('NBR_F1')",
     "dNBR_F1 = NBR_F1.subtract(minpost64.select('NBR')).rename('dNBR_F1')",
     "# RBR Min 64 Day Post ",
     "RBR_F1pre = minpre64.select('RBR').rename('RBR_F1pre')",
     "RBR_F1 = dNBR_F1.divide(RBR_F1pre).rename('RBR_F1')",
     
     "# Mosaic the visualization layers and display (or export).",
     "# Original data",
     "A1_CSI = ee.ImageCollection([CSI_A1]).mosaic()",
     "A1_RdNBR = ee.ImageCollection([RdNBR_A1]).mosaic()",
     "A1_dNBR = ee.ImageCollection([dNBR_A1]).mosaic()",
     "A1_RBR = ee.ImageCollection([RBR_A1]).mosaic()",
     "# Seasonal Post ",
     "B1_CSI = ee.ImageCollection([CSI_B1]).mosaic()",
     "B1_RdNBR = ee.ImageCollection([RdNBR_B1]).mosaic()",
     "B1_dNBR = ee.ImageCollection([dNBR_B1]).mosaic()",
     "B1_RBR = ee.ImageCollection([RBR_B1]).mosaic()",
     "# Maximum Seasonal",
     "C1_CSI = ee.ImageCollection([CSI_C1]).mosaic()",
     "C1_RdNBR = ee.ImageCollection([RdNBR_C1]).mosaic()",
     "C1_dNBR = ee.ImageCollection([dNBR_C1]).mosaic()",
     "C1_RBR = ee.ImageCollection([RBR_C1]).mosaic()",
     "# Minimum Seasonal",
     "D1_CSI = ee.ImageCollection([CSI_D1]).mosaic()",
     "D1_RdNBR = ee.ImageCollection([RdNBR_D1]).mosaic()",
     "D1_dNBR = ee.ImageCollection([dNBR_D1]).mosaic()",
     "D1_RBR = ee.ImageCollection([RBR_D1]).mosaic()",
     "# Adjusted Indicies",
     "E1_RBR = ee.ImageCollection([RBR_E1]).mosaic()",
     "F1_dNBR = ee.ImageCollection([dNBR_F1]).mosaic()",
     "F1_RBR = ee.ImageCollection([RBR_F1]).mosaic()",
     
     "#Set Visualisation Parameters",
     "CSIparams = {'min': 0, 'max': 1, 'palette': ['#FFFFFF', '#696969', '#000000']}",
     "RdNBRparams = {'min': 0, 'max': 2, 'palette': ['#4682B4', '#FAFAD2', '#FF5400','#C71585']}",
     "dNBRparams = {'min': 0, 'max': 0.5, 'palette': ['#4682B4', '#FAFAD2', '#FF5400','#C71585']}",
     "RBRparams = {'min': 0, 'max': 2, 'palette': ['#4682B4', '#FAFAD2', '#FF5400','#C71585']}",
     "RBRModparams = {'min': 0, 'max': 1, 'palette': ['#4682B4', '#FAFAD2', '#FF5400','#C71585']}"
   ]
  },

{
  "cell_type": "code",
   "execution_count": 1,
   "id": "youfind6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clip the fire boundary you want to catergorize",
     "#CSI",
     "CSI_A1F = A1_CSI.clip(WFg)",
     "CSI_B1F = B1_CSI.clip(WFg)",
     "CSI_C1F = C1_CSI.clip(WFg)",
     "CSI_D1F = D1_CSI.clip(WFg)"
     "#RdNBR",
     "RdNBR_A1F = A1_RdNBR.clip(WFg)",
     "RdNBR_B1F = B1_RdNBR.clip(WFg)",
     "RdNBR_C1F = C1_RdNBR.clip(WFg)",
     "RdNBR_D1F = D1_RdNBR.clip(WFg)",
     "#dNBR",
     "dNBR_A1F = A1_dNBR.clip(WFg)",
     "dNBR_B1F = B1_dNBR.clip(WFg)",
     "dNBR_C1F = C1_dNBR.clip(WFg)",
     "dNBR_D1F = D1_dNBR.clip(WFg)",
     "#RBR",
     "RBR_A1F = A1_RBR.clip(WFg)",
     "RBR_B1F = B1_RBR.clip(WFg)",
     "RBR_C1F = C1_RBR.clip(WFg)",
     "RBR_D1F = D1_RBR.clip(WFg)",
     "# Adjusted",
     "RBR_E1F = E1_RBR.clip(WFg)",
     "dNBR_F1F = F1_dNBR.clip(WFg)",
     "RBR_F1F = F1_RBR.clip(WFg)",
   ]
  },
{
  "cell_type": "code",
   "execution_count": 1,
   "id": "this5thd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a legend for maps to use",
     "legend_dict = {",
     "'Unburnt': '#4682B4',",
     "'Low': '#FAFAD2',",
     "'Moderate': '#FF5400',",
     "'High': '#C71585'}",
     "Map.add_legend(title="Burn Severity", legend_dict=legend, position='bottomleft')",
     
     "############### Map #####################",
     "# put it on the map",
     "x,y = fire_poly.centroid().getInfo()['geometry']['coordinates']"
     "# call geemap for plotting "
     "Map = geemap.Map(center=(y, x), zoom = 12, basemap = 'SATELLITE')"
     "# add the fire polygon of interest"
     "#Map.addLayer(fire_poly)"
     
     "#Add a Legend"
     "Map.add_legend(title="Burn Severity", legend_dict=legend_dict, position='bottomleft')"

     "'''To view the indices of your choice, simply comment the indicies you don't want to display, or view them all at once'''"
     "# CSI"
     "Map.addLayer(CSI_A1F, CSIparams, 'CSI_A1')"
     "Map.addLayer(CSI_B1F, CSIparams, 'CSI_B1') "
     "Map.addLayer(CSI_C1F, CSIparams, 'CSI_C1')"
     "Map.addLayer(CSI_D1F, CSIparams, 'CSI_D1')"
     "#RdNBR"
     "Map.addLayer(RdNBR_A1F, RdNBRparams, 'RdNBR_A1')"
     "Map.addLayer(RdNBR_B1F, RdNBRparams, 'RdNBR_B1')"
     "Map.addLayer(RdNBR_C1F, RdNBRparams, 'RdNBR_C1')"
     "Map.addLayer(RdNBR_D1F, RdNBRparams, 'RdNBR_D1')"
     "#dNBR"
     "Map.addLayer(dNBR_A1F, dNBRparams, 'dNBR_A1')"
     "Map.addLayer(dNBR_B1F, dNBRparams, 'dNBR_B1')"
     "Map.addLayer(dNBR_C1F, dNBRparams, 'dNBR_C1')"
     "Map.addLayer(dNBR_D1F, dNBRparams, 'dNBR_D1')"
     "#RBR"
     "Map.addLayer(RBR_A1F, RBRparams, 'RBR_A1')"
     "Map.addLayer(RBR_B1F, RBRparams, 'RBR_B1')"
     "Map.addLayer(RBR_C1F, RBRparams, 'RBR_C1')"
     "Map.addLayer(RBR_D1F, RBRparams, 'RBR_D1')"
     "# Adjusted"
     "Map.addLayer(RBR_E1F, RBRparams, 'RBR_E1')"
     "Map.addLayer(dNBR_F1F, dNBRparams, 'dNBR_F1')"
     "Map.addLayer(RBR_F1F, RBRModparams, 'RBR_F1')"
     
     "Map"
   ]
  },

   


